{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Segmentation Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation maps are 2D arrays in which every spatial position is assigned to exactly one class. They are represented in `imgaug` using `imgaug.augmentables.segmaps.SegmentationMapsOnImage`. The class is instantiated as `SegmentationMapsOnImage(arr, shape)`. `arr` contains the 2D segmentation map and `shape` is the shape of the corresponding *image* (not of the segmentation map array!). The class is called \"...MapsOnImage\" and not \"...MapOnImage\", because you can actually provide many segmentation maps for the same image (provided they all have the same height and width). That means that `arr` may have the shape `(H,W)` or `(H,W,1)`, but it can also have shape `(H,W,C)` with `C>1`. That is useful for e.g. stacked boolean masks or instance segmentation maps (one map of instances per class).\n",
    "\n",
    "Analogous to the constructor arguments, `SegmentationMapsOnImage` has the attributes `.shape` (shape of the corresponding image) and `.arr` (internal segmentation map representation).\n",
    "\n",
    "Noteworthy methods of `SegmentationMapsOnImage` are:\n",
    "  * `get_arr()`: Converts the internal representation of the segmentation map to the same shape and dtype as was originally provided to the constructor. (The internal representation is of shape `(H,W,C)` (with possibly `C=1`) and dtype `int32`.)\n",
    "  * `draw([size], [colors])`: Converts the segmentation map to an RGB image.\n",
    "  * `draw_on_image(image, [alpha], [resize], [colors], [draw_background])`: Converts the segmentation map to an RGB image and blends it with a provided image.\n",
    "  * `pad([top], [right], [bottom], [left], [mode], [cval])`: Pad the segmentation map on its sides.\n",
    "  * `pad_to_aspect_ratio(aspect_ration, [mode], [cval], [return_pad_amounts])`: Pad the segmentation map to an aspect ratio (`ratio=width/height`).\n",
    "  * `resize(sizes, [interpolation])`: Resize the segmentation map to the provided size. Uses by default nearest neighbour interpolation.\n",
    "\n",
    "To augment segmentation maps, use `augment_segmentation_maps()`, which is offered by all augmenters. It expects a single `SegmentationMapsOnImage` instance or a `list` of `SegmentationMapsOnImage` instances. You may also call `augment(image=..., segmentation_map=...)` or its alias `__call__(images=..., segmentation_maps=...)` (e.g. `Affine(scale=1.5)(images=..., segmentation_maps=...)`), which both allow to provide the segmentation map as an int-like array.\n",
    "\n",
    "For more details, see the [API](https://imgaug.readthedocs.io/en/latest/source/api.html): [imgaug.augmentables.segmaps.SegmentationMapsOnImage](https://imgaug.readthedocs.io/en/latest/source/api_imgaug.html#imgaug.augmentables.segmaps.SegmentationMapsOnImage), [imgaug.augmenters.meta.Augmenter.augment_segmentation_maps()](https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Augmenter.augment_segmentation_maps), [imgaug.augmenters.meta.Augmenter.augment()](https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Augmenter.augment).\n",
    "\n",
    "For drawing routines `SegmentationMapsOnImage` uses a predefined set of colors. These are currently saved in the constant `SegmentationMapsOnImage.DEFAULT_SEGMENT_COLORS`. They will likely be replaced at some point in the future by a matplotlib colormap.\n",
    "\n",
    "**Important**: `imgaug`'s segmentation map augmentation is geared towards **ground truth** outputs. As such, only augmentation techniques that change the image geometry will be applied to segmentation maps, even when other augmentation techniques are part of a pipeline. Examples for that are e.g. horizontal flips or affine transformations. To also apply non-geometric augmentation techniques, feed the segmentation map array through `augmenter.augment_images()` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Example Segmentation Map from Polygons Given as Points\n",
    "\n",
    "The goal of our first example is to load an image, create a segmentation map and augment both of them. Let's first load and visualize our example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import imgaug as ia\n",
    "%matplotlib inline\n",
    "\n",
    "image = imageio.imread(\"https://upload.wikimedia.org/wikipedia/commons/f/f4/Tamias_striatus_CT.jpg\")\n",
    "image = ia.imresize_single_image(image, 0.15)\n",
    "print(image.shape)\n",
    "ia.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a segmentation map for that image. We will create two classes, one for the tree (bottom) and one for the chipmunk (center). Everything else will be background. Both classes will be created as polygons and then drawn on a segmentation map array. First, we define the four corner points of the tree polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imgaug.augmentables.kps import KeypointsOnImage\n",
    "\n",
    "tree_kps_xy = np.float32([\n",
    "    [0, 300],  # left top of the tree\n",
    "    [image.shape[1]-1, 230],  # right top\n",
    "    [image.shape[1]-1, image.shape[0]-1],  # right bottom\n",
    "    [0, image.shape[0]-1]  # left bottom\n",
    "])\n",
    "\n",
    "# visualize\n",
    "kpsoi_tree = KeypointsOnImage.from_xy_array(tree_kps_xy, shape=image.shape)\n",
    "ia.imshow(kpsoi_tree.draw_on_image(image, size=13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to create the chipmunk polygon. That one requires significantly more corner points, but the underlying method is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipmunk_kps_xy = np.float32([\n",
    "    [200, 50],  # left ear, top (from camera perspective)\n",
    "    [220, 70],\n",
    "    [260, 70],\n",
    "    [280, 50],  # right ear, top\n",
    "    [290, 80],\n",
    "    [285, 110],\n",
    "    [310, 140],\n",
    "    [330, 175], # right of cheek\n",
    "    [310, 260], # right of right paw\n",
    "    [175, 275], # left of left paw\n",
    "    [170, 220],\n",
    "    [150, 200],\n",
    "    [150, 170], # left of cheek\n",
    "    [160, 150],\n",
    "    [186, 120], # left of eye\n",
    "    [185, 70]\n",
    "])\n",
    "\n",
    "# visualize\n",
    "kpsoi_chipmunk = KeypointsOnImage.from_xy_array(chipmunk_kps_xy, shape=image.shape)\n",
    "ia.imshow(kpsoi_chipmunk.draw_on_image(image, size=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we convert both sets of corner points to instances of `imgaug.augmentables.polys.Polygon`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug.augmentables.polys import Polygon\n",
    "\n",
    "# create polygons\n",
    "poly_tree = Polygon(kpsoi_tree.keypoints)\n",
    "poly_chipmunk = Polygon(kpsoi_chipmunk.keypoints)\n",
    "\n",
    "# visualize polygons\n",
    "ia.imshow(np.hstack([\n",
    "    poly_tree.draw_on_image(image),\n",
    "    poly_chipmunk.draw_on_image(image)\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert the two polygons to a single segmentation map. We do this by first creating an empty `(H,W,3)` array for our three classes (background, tree, chipmunk). Then we draw the tree and chipmunk polygons onto that array as if it was an image. We use 100% green (tree) and 100% blue (chipmunk) colors, thereby drawing the tree only into the second image channel and the chipmunk only into the third channel. Then we merge the three channels to a single segmentation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty segmentation map for classes: background, tree, chipmunk\n",
    "segmap = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "# draw the tree polygon into the second channel\n",
    "segmap = poly_tree.draw_on_image(\n",
    "    segmap,\n",
    "    color=(0, 255, 0),\n",
    "    alpha=1.0, alpha_lines=0.0, alpha_points=0.0)\n",
    "\n",
    "# draw the chipmunk polygon into the third channel\n",
    "segmap = poly_chipmunk.draw_on_image(\n",
    "    segmap,\n",
    "    color=(0, 0, 255),\n",
    "    alpha=1.0, alpha_lines=0.0, alpha_points=0.0)\n",
    "\n",
    "# merge the three channels to a single one\n",
    "segmap = np.argmax(segmap, axis=2)\n",
    "\n",
    "# change dtype from int64 to int32, as int32 is the allowed maximum in SegmentationMapsOnImage\n",
    "segmap = segmap.astype(np.int32)\n",
    "\n",
    "# draw statistics about our segmentation map\n",
    "print(\"Shape:\", segmap.shape, \"min value:\", segmap.min(), \"max value:\", segmap.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to call `imgaug.augmentables.segmaps.SegmentationMapsOnImage` with that segmentation map and can draw the result on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# convert array to SegmentationMapsOnImage instance\n",
    "segmap = SegmentationMapsOnImage(segmap, shape=image.shape)\n",
    "\n",
    "# visualize\n",
    "# Note that the segmentation map drawing methods return lists of RGB images.\n",
    "# That is because the segmentation map may have multiple channels\n",
    "# -- the C in (H,W,C) -- and one image is drawn for each of these channels.\n",
    "# We have C=1 here, so we get a list of a single image here and acces that via [0].\n",
    "ia.imshow(segmap.draw_on_image(image)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the Example Segmentation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the example segmentation map, our next goal is to augment it (and the corresponding image). First, we create the augmentation sequence, consisting of a bit of coarse dropout (sets rectangular areas to zero), an affine transformation and an elastic transformation (water-like effect). Note that only `Affine` and `ElasticTransformation` will actually change the segmentation map, as segmentation map augmentation is only affected by augmenters that change the image geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "ia.seed(2)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.CoarseDropout(0.1, size_percent=0.2),\n",
    "    iaa.Affine(rotate=(-30, 30)),\n",
    "    iaa.ElasticTransformation(alpha=10, sigma=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to apply the augmentation pipeline to both segmentation map and image. To do that we use `seq.augment(image=..., segmentation_maps=...)` or its shortcut `seq(image=..., segmentation_maps=...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_aug, segmap_aug = seq(image=image, segmentation_maps=segmap)\n",
    "\n",
    "# visualize\n",
    "ia.imshow(np.hstack([\n",
    "    segmap_aug.draw_on_image(image_aug)[0],  # show blend of (augmented) image and segmentation map\n",
    "    segmap_aug.draw()[0]  # show only the augmented segmentation map\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the segmentation map is affected by the affine transformation (i.e. rotated) and the elastic transformation (i.e. water-like effect, here fairly noisy). It is not affected by coarse dropout as that augmenter does not change the image geometry. (Note also that coarse dropout here did drop rectangular areas, which appear non-rectangular as the elastic transformation was applied afterwards and roughened up the rectangles.)\n",
    "\n",
    "The elastic transformation above is quite noisy, making it hard to see whether image and segmentation map augmentation are aligned. Let's execute it on its own with less noisy settings. Let's also generate one output image where the input image and segmentation map are both augmented on their own, which will result in different sampled random values and hence unaligned augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.ElasticTransformation(alpha=200, sigma=10)\n",
    "\n",
    "# with alignment (correct)\n",
    "image_aug, segmap_aug = aug(image=image, segmentation_maps=segmap)\n",
    "\n",
    "# without to_deterministic() (incorrect)\n",
    "image_aug_unaligned = aug(image=image)\n",
    "segmap_aug_unaligned = aug(segmentation_maps=segmap)\n",
    "\n",
    "ia.imshow(\n",
    "    np.hstack([\n",
    "        segmap_aug.draw_on_image(image_aug, alpha=0.4)[0],\n",
    "        segmap_aug.draw_on_image(image_aug_unaligned, alpha=0.4)[0]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are significant differences between image and segmentation map in the right image (well visible e.g. for the tree). While in the version with aligned sampled values (left) image and segmentation map match well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Segmentation Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation maps often have to be resized, e.g. to create lower-resolution ground truth outputs for a network. This can be done using the `resize()` method. The following example uses the method to resize a segmentation map to 1/4th of its original size. Alternatively, a fixed size can also be used (e.g. `(100, 200)` to get an output map with height 100 and width 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmap_small = segmap.resize(0.25)\n",
    "print(\"Before:\", segmap.arr.shape, \"After:\", segmap_small.arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(segmap_small.draw()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the segmentation map before and after resizing, projected onto the image (i.e. again resized, back to the image size). The map after downscaling+upscaling (right) is visibly more coarse than the one without (left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(\n",
    "    np.hstack([\n",
    "        segmap.draw_on_image(image)[0],\n",
    "        segmap_small.draw_on_image(image)[0]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Segmentation Maps Smaller than their Corresponding Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite common that the ground truth output segmentation map of a network is smaller than the input image. This scenario is handled automatically by `imgaug`. Simply feed the smaller-sized segmentation map through the augmentation pipeline as if it was of the same size as the image. Just make sure that the `.shape` attribute of `SegmentationMapsOnImage` matches the input image size (as it always should).\n",
    "\n",
    "The following code block augments the example image and the previously downscaled segmentation map. We first print the array shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image size: %s Segmentation Map size: %s (on image with shape: %s)\" % (\n",
    "    image.shape, segmap_small.arr.shape, segmap_small.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we augment and visualize the image and the small scale segmentation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.ElasticTransformation(alpha=200, sigma=10)\n",
    "\n",
    "image_aug, segmap_small_aug = aug(image=image, segmentation_maps=segmap_small)\n",
    "\n",
    "ia.imshow(segmap_small_aug.draw_on_image(image_aug, alpha=0.4)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation of smaller sized segmentation maps still works, even if parameters denote pixel values. The following example shows a common scenario where the image is cropped by a set amount of pixels (50 at the bottom, 200 on the left side). The pixel amounts are transformed to corresponding pixel amounts for the smaller sized segmentation map. (For comparison, we also augment the image-sized segmentation map.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.Crop(px=(0, 0, 50, 200))  # (top, right, bottom, left)\n",
    "\n",
    "# We have to augment two segmentation maps with the exactly same random values.\n",
    "# This is why we switch to deterministic mode here, which resets the random state after\n",
    "# each augmentation.\n",
    "# (Due to using non-stochastic crop values, we could also skip this, but it seems cleaner\n",
    "# to do it.)\n",
    "aug_det = aug.to_deterministic()\n",
    "image_aug = aug_det.augment_image(image)  # augment image\n",
    "segmap_aug = aug_det.augment_segmentation_maps(segmap)  # augment normal-sized segmentation map\n",
    "segmap_small_aug = aug_det.augment_segmentation_maps(segmap_small)  # augment smaller-sized segmentation map\n",
    "\n",
    "ia.imshow(np.hstack([\n",
    "    segmap_aug.draw_on_image(image_aug, alpha=0.4)[0],  # draw augmented normal-sized segmentation map\n",
    "    segmap_small_aug.draw_on_image(image_aug, alpha=0.4)[0]  # draw augmented smaller-sized segmentation map\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though both augmented segmentation maps (left: normal scale, right: small scale) were here automatically upscaled to the image size and hence both *seem* to have the same resolution, the smaller segmentation map (right) has visibly rougher edges due to its actually lower resolution *before automatic upscaling*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Augmented Segmentation Maps to Numpy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internal array in `SegmentationMapsOnImage`, accessible via the `.arr` attribute, has by default dtype `int32` and shape `(H,W,C)`. If the original array that was to the constructor of `SegmentationMapsOnImage` had the same dtype and shape, you may simply access `.arr`. Otherwise, you should call `get_arr()`, which automatically converts `.arr` to your original dtype and shape. (To be precise: It doesn't convert to the original shape, but to the original number of dimensions. The shape might have changed after creating the object due to resizing operations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = segmap.arr\n",
    "arr_int = segmap.get_arr()\n",
    "\n",
    "print(\"[segmap.arr]       Shape:\", arr.shape, \"dtype:\", arr.dtype)\n",
    "print(\"[segmap.get_arr()] Shape:\", arr_int.shape, \"dtype:\", arr_int.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad Segmentation Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to images, segmentation maps can be padded using `SegmentationMapsOnImage.pad()`. Padding supports several different modes, with the most appropriate ones often being `constant` (pad with a constant value `cval`) and `edge` (keep repeating the class ids around the image borders). The following example showcases both of these modes. It first pads both image and segmentation map with a constant value of `0` (left image) and afterwards pads them using `edge` mode (right image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pad_constant = ia.pad(image, left=100, top=20)  # mode=\"constant\" and cval=0 are the defaults of pad()\n",
    "segmap_pad_constant = segmap.pad(left=100, top=20)    # mode=\"constant\" and cval=0 are the defaults of pad()\n",
    "\n",
    "image_pad_edge = ia.pad(image, left=100, top=20, mode=\"edge\")\n",
    "segmap_pad_edge = segmap.pad(left=100, top=20, mode=\"edge\")\n",
    "\n",
    "ia.imshow(np.hstack([\n",
    "    segmap_pad_constant.draw_on_image(image_pad_constant, alpha=0.5)[0],\n",
    "    segmap_pad_edge.draw_on_image(image_pad_edge, alpha=0.5)[0],\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using edge mode, one has to be careful with classes that do not fully extend to the image edges. The below example pads image and segmentation map using `edge` mode, but now pads on the left *and* the right side. While the padding of the segmentation map behaves as expected on the left side, it does not extend the class on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_wide = ia.pad_to_aspect_ratio(image, 3.0, mode=\"edge\")\n",
    "segmap_wide = segmap.pad_to_aspect_ratio(3.0, mode=\"edge\")\n",
    "\n",
    "ia.imshow(segmap_wide.draw_on_image(image_wide, alpha=0.5)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the above problem is that the drawing routine, which was used to add the tree polygon to the segmentation map, stopped just slightly short of the right image edge. The output below demonstrates this. It shows the class ids for the last five columns of the segmentation map. The tree class extends only up to the second to last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segmap.arr[:, -5:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Segmentation Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above examples already made use of the drawing methods offered by `SegmentationMapsOnImage`. One of these methods is `draw()`, which converts the segmentation map to a list of RGB images. For a `(H,W,C)` segmentation map it returns `C` RGB images. In most cases, `C` is `1` and hence the list only contains a single image.\n",
    "The example below uses the `draw()` method to visualize a segmentation map before and after augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmap_aug = iaa.ElasticTransformation(alpha=50, sigma=5).augment_segmentation_maps(segmap)\n",
    "ia.imshow(np.hstack([\n",
    "    segmap.draw()[0],\n",
    "    segmap_aug.draw()[0],\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case other colors than the default ones are desired, the parameter `colors` can be used to define them. It expects a list with one iterable per class. Each iterable must contain three `uint8` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(np.hstack([\n",
    "    segmap.draw()[0],\n",
    "    segmap.draw(colors=[(255, 255, 255), (128, 128, 0), (0, 0, 128)])[0],\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easy scaling, `draw` also offers a `size` parameter, which can be set to e.g. a `(height, width)` tuple or a fraction (relative to the size saved in `SegmentationMapsOnImage.shape`), as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(segmap.draw(0.1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `draw_on_image()` is similar to `draw()`, but is geared towards visualizing the segmentation map ontop of another image. The method performs the following three steps: (1) It converts the segmentation map to a list of RGB images (like `draw()` does), then (2) it resizes each of them to the same size as the provided base image (or it resizes the base image to the drawn segmentation map sizes, depending on arguments), and then (3) it alpha-blends the image and segmentation map images.\n",
    "The following example showcases `draw_on_image()`. Note that the background (class id `0`) is by default set to transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(segmap.draw_on_image(image)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the alpha blending step, the segmentation map's opacity can be controlled using the `alpha` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(np.hstack([\n",
    "    segmap.draw_on_image(image, alpha=0.25)[0],\n",
    "    segmap.draw_on_image(image, alpha=0.50)[0],\n",
    "    segmap.draw_on_image(image, alpha=0.75)[0]\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, pixels with the background class id `0` are set to transparent, i.e. they show the base image. These background class pixels of the segmentation map image can also be drawn by setting `draw_background=True`. The default color for the background is black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(segmap.draw_on_image(image, draw_background=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, using `background_class_id` it is possible to control which class is supposed to be treated as background and hence ignored in the blending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(segmap.draw_on_image(image, draw_background=False, background_class_id=2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`draw_on_image()` can handle different sizes between image and segmentation map. By default, the segmentation map is resized to the image size using nearest neighbour interpolation. The following example uses a segmentation map with 20% of the image size to show this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmap_small = segmap.resize(0.2)\n",
    "print(segmap_small.arr.shape, image.shape)\n",
    "\n",
    "ia.imshow(segmap_small.draw_on_image(image)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of resizing the segmentation map to the image, the image can instead be resized to the segmentation map's size using the `resize` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(segmap_small.draw_on_image(image, resize=\"image\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Segmentation Maps with Non-Geometric Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the segmentation map augmentation using `augment(segmentation_maps=...)` or `augment_segmentation_maps(...)` is geared towards ground truth augmentation and hence only applies geometry-affecting augmentations. If that limitation is undesired, the segmentation maps have to be treated as raw arrays and fed through `augment(images=...)` or `augment_images(...)`. The following code block first introduces an example using ordinary `augment(image=..., segmentation_maps=...)`. In second code block, this is then changed to using two times `augment(image=...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example augmentation pipeline\n",
    "aug = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-20, 20)),  # only this affects segmentation maps via augment_segmentation_maps()\n",
    "    iaa.CoarseDropout(0.2, size_percent=0.1),\n",
    "    iaa.AdditiveGaussianNoise(scale=0.2*255)\n",
    "])\n",
    "\n",
    "# standard way of augmenting segmentation maps via augment_segmentation_maps()\n",
    "image_aug, segmap_aug = aug(image=image, segmentation_maps=segmap)\n",
    "\n",
    "# visualize before/after\n",
    "ia.imshow(np.hstack([\n",
    "    segmap_aug.draw_on_image(image_aug)[0],\n",
    "    segmap_aug.draw()[0]\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we augment the segmentation maps with `Affine` and the non-geometric `CoarseDropout`. However, we do not want to apply `AdditiveGaussianNoise` to the segmentation maps, only to the images. A fairly simple way to achieve this is to use two different augmentation pipelines, one for images and one for segmentation maps. We then initialize each augmenter with a hand-adjusted seed via `random_state=<seed>`. By choosing matching seeds between the two pipelines, we can ensure that the augmenters draw the same samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation pipeline for images\n",
    "aug_images = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-20, 20), random_state=1),\n",
    "    iaa.CoarseDropout(0.2, size_percent=0.05, random_state=2),\n",
    "    iaa.AdditiveGaussianNoise(scale=0.2*255, random_state=3)\n",
    "], random_state=4)\n",
    "\n",
    "# augmentation pipeline for segmentation maps - with coarse dropout, but without gaussian noise\n",
    "aug_segmaps = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-20, 20), random_state=1),\n",
    "    iaa.CoarseDropout(0.2, size_percent=0.05, random_state=2)\n",
    "], random_state=4)\n",
    "\n",
    "# First, augment image.\n",
    "image_aug = aug_images(image=image)\n",
    "\n",
    "# Second, augment segmentation map.\n",
    "# We convert to uint8 as that dtype has usually best support and hence is safest to use.\n",
    "segmap_arr_aug = aug_segmaps(image=segmap.get_arr().astype(np.uint8))\n",
    "segmap_aug = SegmentationMapsOnImage(segmap_arr_aug, shape=segmap.shape)\n",
    "\n",
    "# visualize\n",
    "ia.imshow(np.hstack([\n",
    "    image_aug,\n",
    "    segmap_aug.draw_on_image(image_aug, alpha=0.5)[0],\n",
    "    segmap_aug.draw()[0]\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when augmenting segmentation maps via `augment(image=...)` or `augment_images(...)`, size differences are not automatically accounted for. So while augmentations via `augment(segmentation_maps=...)` or `augment_segmentation_maps(...)` can be done with segmentation maps that are smaller than the corresponding images, the sizes should match if using the former image-based methods. Otherwise, the two pipelines have to be manually adjusted to match despite different sizes. E.g. `Crop` should then be used with fractions instead of raw pixel values as arguments -- or alternatively the pixel values have to be different between the pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (imgaug37)",
   "language": "python",
   "name": "imgaug37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
